{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa9c3d71-9033-413d-b4c0-aa5ae20bb16a",
   "metadata": {},
   "source": [
    "# Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbc30b0-6efe-47a5-9a7f-14aef3175d2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install clearml\n",
    "# !pip install xgboost\n",
    "# !pip install pandas\n",
    "# !pip install scikit-learn\n",
    "# !pip install matplotlib\n",
    "# !pip install torch\n",
    "# !pip install tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f548a646-a46d-4a45-9228-0719afea8c28",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c1e42ff7-50b6-4bfd-ab0e-1502e8b0366f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress report #196 completed, sleeping for 0.25 minutes\n",
      "Progress report #197 completed, sleeping for 0.25 minutes\n"
     ]
    }
   ],
   "source": [
    "import clearml\n",
    "from clearml.automation import UniformParameterRange, UniformIntegerParameterRange\n",
    "from clearml.automation import HyperParameterOptimizer\n",
    "from clearml.automation import GridSearch\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import joblib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96550d1a-d1be-4625-8004-32a5fc176b07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 52741595136 bytes\n",
      "used: 19005018112 bytes\n",
      "free: 31519010816 bytes\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "d = psutil.disk_usage('/')\n",
    "print(f\"total: {d.total} bytes\")\n",
    "print(f\"used: {d.used} bytes\")\n",
    "print(f\"free: {d.free} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f714b4c8-2035-43b6-946a-ba5c382f42e1",
   "metadata": {},
   "source": [
    "# Connect to Browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3016681c-7264-402c-b447-268e84bb8d2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CLEARML_WEB_HOST=https://app.clear.ml\n",
      "env: CLEARML_API_HOST=https://api.clear.ml\n",
      "env: CLEARML_FILES_HOST=https://files.clear.ml\n",
      "env: CLEARML_API_ACCESS_KEY=CEXP8BVY587LDKN4L2N6\n",
      "env: CLEARML_API_SECRET_KEY=QzzgTEb2qDtZTg8JwPPXVSe4lMiMQiGJjFTwanDuIqimPJjwhR\n"
     ]
    }
   ],
   "source": [
    "%env CLEARML_WEB_HOST=https://app.clear.ml\n",
    "%env CLEARML_API_HOST=https://api.clear.ml\n",
    "%env CLEARML_FILES_HOST=https://files.clear.ml\n",
    "%env CLEARML_API_ACCESS_KEY=CEXP8BVY587LDKN4L2N6\n",
    "%env CLEARML_API_SECRET_KEY=QzzgTEb2qDtZTg8JwPPXVSe4lMiMQiGJjFTwanDuIqimPJjwhR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0887e65d-ed9b-4ebb-809e-1484fcbbcc73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clearml.browser_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a58d6b03-d7bd-49c6-830a-f03c44069e37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from clearml import Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24c2e6d-f52f-4c2f-9a1a-76e8445f1208",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5222adba-db63-4894-8233-09520ffeb748",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<clearml.backend_api.session.callresult.CallResult at 0x7fed9ffd5090>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress report #25 completed, sleeping for 0.25 minutes\n",
      "Progress report #26 completed, sleeping for 0.25 minutes\n",
      "Progress report #27 completed, sleeping for 0.25 minutes\n",
      "Progress report #28 completed, sleeping for 0.25 minutes\n",
      "Progress report #29 completed, sleeping for 0.25 minutes\n",
      "Progress report #30 completed, sleeping for 0.25 minutes\n"
     ]
    }
   ],
   "source": [
    "# Task.get_task('128a20327ce540c186682da2c66deea1').delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0737ba00-2d7c-4d3b-abfe-00fdfecee83e",
   "metadata": {},
   "source": [
    "## Create ClearML Task and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffed0c1-4ed5-4dbc-a627-c0ee2408d11b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "task_xgb = Task.init(project_name=\"lab_03_devops\", \n",
    "                 task_name=\"xgb_cricket_prediction\", \n",
    "                 output_uri=True)\n",
    "all_projects = Task.get_projects()\n",
    "lab_03_devops_project = all_projects[-1]\n",
    "print(lab_03_devops_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35768fff-abec-49b1-9cd7-ba6a78679df0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ipl_df = pd.read_csv('data/ipl_data.csv', low_memory=True)\n",
    "ipl_df.drop(['id'], axis=1, inplace=True)\n",
    "print(ipl_df.shape, ipl_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b8f9d4-952d-41e0-bf46-e0bfd23df501",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ipl_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d10454-141c-437b-8ca2-dce7d10ce53c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ipl_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd1133-6d81-4b0e-9d4c-35657ff8eb06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols_to_convert_to_category = ipl_df.columns[:-1]\n",
    "ipl_df[cols_to_convert_to_category] = ipl_df[cols_to_convert_to_category].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8473b706-23f0-49e1-b65c-48f423edb1b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ipl_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aac991-223f-4feb-98f6-b547bb09aa17",
   "metadata": {},
   "source": [
    "## Model Train, Test and Basic Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821e645a-f89f-4156-bebc-550cce5a9a07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = ipl_df.drop(['outcome'], axis=1)\n",
    "y = ipl_df['outcome']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "data_train_matrix = xgb.DMatrix(X_train, label=y_train, enable_categorical=True)\n",
    "data_val_matrix = xgb.DMatrix(X_val, label=y_val, enable_categorical=True)\n",
    "data_test_matrix = xgb.DMatrix(X_test, label=y_test, enable_categorical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9307ab-1cb3-4b31-ad7e-efdef471f16e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth': 2,\n",
    "    'learning_rate': 0.1,\n",
    "    'objective': 'binary:logistic',\n",
    "    'nthread': 4,\n",
    "    'colsample_bytree': 0.5,\n",
    "    'eval_metric': 'logloss',\n",
    "    'subsample': 0.5,\n",
    "    'gamma':0.1\n",
    "}\n",
    "task_xgb.connect(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1360b9ba-e8a3-49a7-a426-e4ec48f5b5eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgb_model = xgb.train(\n",
    "        params,\n",
    "        data_train_matrix,\n",
    "        num_boost_round=150,\n",
    "        evals=[(data_train_matrix, \"train\"), (data_val_matrix, \"eval\")],\n",
    "        verbose_eval=0,\n",
    ")\n",
    "xgb_model.save_model(\"best_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540eceed-ec56-454f-8fa7-33d8e82f60b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred_probas = xgb_model.predict(data_test_matrix)\n",
    "y_pred = [1 if p > 0.5 else 0 for p in y_pred_probas]\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"accuracy = {round(accuracy, 3)}\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "ConfusionMatrixDisplay(cm).plot(ax=plt.gca())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cde6ea-752a-4b1f-82c4-4083041ecf87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "task_xgb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7efea5-3048-4143-9530-b62489043730",
   "metadata": {},
   "source": [
    "# HPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac2afc3-04ec-49a1-ae1f-bd529754c9aa",
   "metadata": {},
   "source": [
    "## Do HPO Search for XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24caf115-e4c1-4643-97f6-80cb12a33b60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgb_task_to_optimize = '0e79f82d492b4019a0230d95f40f2cbc'\n",
    "\n",
    "xgb_optimizer = HyperParameterOptimizer(\n",
    "    base_task_id=xgb_task_to_optimize,\n",
    "    hyper_parameters=[\n",
    "        UniformIntegerParameterRange('General/max_depth', min_value=3, max_value=7, step_size=2),\n",
    "        UniformParameterRange('General/learning_rate', min_value=0.001, max_value=0.1, step_size=50),\n",
    "        UniformParameterRange('General/colsample_bytree', min_value=0.5, max_value=1, step_size=0.1),\n",
    "        UniformParameterRange('General/subsample', min_value=0.5, max_value=1, step_size=0.1),\n",
    "        UniformParameterRange('General/gamma', min_value=0.1, max_value=0.3, step_size=0.1),\n",
    "    ],\n",
    "    # setting the objective metric we want to maximize/minimize\n",
    "    objective_metric_title='train',\n",
    "    objective_metric_series='logloss',\n",
    "    objective_metric_sign='min',  # maximize or minimize the objective metric\n",
    "\n",
    "    # setting optimizer - clearml supports GridSearch, RandomSearch, OptimizerBOHB and OptimizerOptuna\n",
    "    optimizer_class=GridSearch,\n",
    "    \n",
    "    # Configuring optimization parameters\n",
    "    # execution_queue='xgb_GridCV_queue',  # queue to schedule the experiments for execution\n",
    "    max_number_of_concurrent_tasks=7,  # number of concurrent experiments\n",
    "    optimization_time_limit=20.,  # set the time limit for the optimization process\n",
    "    compute_time_limit=60,  # set the compute time limit (sum of execution time on all machines)\n",
    "    total_max_jobs=20,  # set the maximum number of experiments for the optimization.  # Converted to total number of iteration for OptimizerBOHB\n",
    "    # min_iteration_per_job=15000,  # minimum number of iterations per experiment, till early stopping\n",
    "    # max_iteration_per_job=150000,  # maximum number of iterations per experiment\n",
    ")\n",
    "\n",
    "xgb_optimizer.set_report_period(0.1)  # setting the time gap between two consecutive reports\n",
    "xgb_optimizer.start()  \n",
    "xgb_optimizer.wait()  # wait until process is done\n",
    "xgb_optimizer.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7fdfc6-a208-44c5-978b-f5fe31323620",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Print Results of HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ce866000-c7cd-4c25-a3c2-a2f75da66722",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress report #191 completed, sleeping for 0.25 minutes\n",
      "Top 3 experiments are:\n",
      "------------------------------------------------\n",
      "Rank = 1: task_id = 0f1678866a784817b876ea00cf4fcea4\n",
      "------------------------------------------------\n",
      "General/max_depth: 3\n",
      "General/learning_rate: 0.1\n",
      "General/objective: binary:logistic\n",
      "General/nthread: 4\n",
      "General/colsample_bytree: 0.5\n",
      "General/eval_metric: logloss\n",
      "General/subsample: 0.5\n",
      "General/gamma: 0.3\n",
      "------------------------------------------------\n",
      "Rank = 2: task_id = 3a05e67814524574b6179a6747407a74\n",
      "------------------------------------------------\n",
      "General/max_depth: 3\n",
      "General/learning_rate: 0.1\n",
      "General/objective: binary:logistic\n",
      "General/nthread: 4\n",
      "General/colsample_bytree: 0.5\n",
      "General/eval_metric: logloss\n",
      "General/subsample: 0.6\n",
      "General/gamma: 0.3\n",
      "------------------------------------------------\n",
      "Rank = 3: task_id = 1643f8bec9604a549dc3bec2d6d0fd63\n",
      "------------------------------------------------\n",
      "General/max_depth: 3\n",
      "General/learning_rate: 0.1\n",
      "General/objective: binary:logistic\n",
      "General/nthread: 4\n",
      "General/colsample_bytree: 0.5\n",
      "General/eval_metric: logloss\n",
      "General/subsample: 0.8\n",
      "General/gamma: 0.1\n",
      "Progress report #192 completed, sleeping for 0.25 minutes\n",
      "Progress report #193 completed, sleeping for 0.25 minutes\n",
      "Progress report #194 completed, sleeping for 0.25 minutes\n",
      "Progress report #195 completed, sleeping for 0.25 minutes\n"
     ]
    }
   ],
   "source": [
    "take_items = lambda d, n: [print(f\"{k}: {d[k]}\") for k in list(d.keys())[:n]]\n",
    "k = 3\n",
    "top_exp = xgb_optimizer.get_top_experiments(top_k=k)\n",
    "print('Top {} experiments are:'.format(k))\n",
    "for n, t in enumerate(top_exp, 1):\n",
    "    print(\"------------------------------------------------\")\n",
    "    print(f\"Rank = {n}: task_id = {t.id}\")\n",
    "    print(\"------------------------------------------------\")\n",
    "    take_items(t.get_parameters(), len(t.get_parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937e1910-5b47-4932-b096-3cc89459b69e",
   "metadata": {},
   "source": [
    "# Deep Learning with Tensorboard and Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012056dd-46eb-4956-a45f-d22972e4a8c1",
   "metadata": {},
   "source": [
    "## Create ML Task and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5654fd88-92e4-4ac1-956c-7d98e7adeb9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "task_nn = Task.init(project_name=\"lab_03_devops\", \n",
    "                 task_name=\"tensorboard_pytorch_cricket_prediction\", \n",
    "                 output_uri=True)\n",
    "all_projects = Task.get_projects()\n",
    "lab_03_devops_project = all_projects[-1]\n",
    "print(lab_03_devops_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d547cb0-ffb4-496f-80b6-ab61b0b12536",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ipl_df = pd.read_csv('data/ipl_data.csv', low_memory=True)\n",
    "ipl_df.drop(['id'], axis=1, inplace=True)\n",
    "print(ipl_df.shape, ipl_df.columns)\n",
    "ipl_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2bd3df-a4b9-4710-9804-a459e910a17b",
   "metadata": {},
   "source": [
    "## Model Train, Test and TensorBoard Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab91dc1-304d-4a21-8cae-ac9d643eb675",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the custom dataset class\n",
    "class IPLDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = torch.FloatTensor(data)\n",
    "        self.labels = torch.FloatTensor(labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "# Get data in desired format and split\n",
    "X, y = ipl_df.iloc[:, :-1], ipl_df.iloc[:, -1]\n",
    "print(X.shape)\n",
    "X = pd.get_dummies(X)\n",
    "print(X.shape)\n",
    "X, y = X.to_numpy(), y.to_numpy()\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "# Instantiate the datasets and dataloaders\n",
    "train_dataset = IPLDataset(X_train, y_train)\n",
    "val_dataset = IPLDataset(X_val, y_val)\n",
    "test_dataset = IPLDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ed9a8a-0c78-4332-b879-bed5a43d2b70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the neural network architecture\n",
    "class IPL_match_outcome_BNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_rate=0.5):\n",
    "        super(IPL_match_outcome_BNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size // 2)\n",
    "        self.fc3 = nn.Linear(hidden_size // 2, hidden_size // 8)\n",
    "        self.fc4 = nn.Linear(hidden_size // 8, 1)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(torch.relu(self.fc1(x)))\n",
    "        x = self.dropout(torch.relu(self.fc2(x)))\n",
    "        x = self.dropout(torch.relu(self.fc3(x)))\n",
    "        x = self.sigmoid(self.fc4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668f24fa-7a6a-4f0a-8550-929c35b19ff6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce282b0-024b-4871-bc5a-ab126937afd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_size = X.shape[1] \n",
    "hidden_size = X.shape[1] // 2\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "num_epochs = 50\n",
    "\n",
    "# Data Loaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Model\n",
    "model = IPL_match_outcome_BNN(input_size, hidden_size)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f1bcbc-c8be-4c9d-b46d-e39e823cfe9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    for inputs, labels in train_dataloader:\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Convert predictions and labels to integers for accuracy calculation\n",
    "        train_predictions = outputs.round().squeeze().detach().cpu().numpy()\n",
    "        train_labels = labels.detach().cpu().numpy()\n",
    "        train_correct += (train_predictions == train_labels).sum()\n",
    "        train_total += len(train_labels)\n",
    "\n",
    "    # Compute the training accuracy\n",
    "    train_accuracy = train_correct / train_total\n",
    "\n",
    "    # Perform validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    for inputs, labels in val_dataloader:\n",
    "        val_outputs = model(inputs)\n",
    "        val_loss += criterion(val_outputs.squeeze(), labels).item()\n",
    "\n",
    "        # Convert predictions and labels to integers for accuracy calculation\n",
    "        val_predictions = val_outputs.round().squeeze().detach().cpu().numpy()\n",
    "        val_labels = labels.detach().cpu().numpy()\n",
    "        val_correct += (val_predictions == val_labels).sum()\n",
    "        val_total += len(val_labels)\n",
    "\n",
    "    # Compute the validation accuracy\n",
    "    val_accuracy = val_correct / val_total\n",
    "    if epoch % 12 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], \\\n",
    "        Train Loss: {train_loss:.4f}, \\\n",
    "        Train Accuracy: {train_accuracy:.4f}, \\\n",
    "        Validation Loss: {val_loss:.4f}, \\\n",
    "        Validation Accuracy: {val_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cb86cb-372b-4c5c-8d3d-a7c30ca51c4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_predictions = []\n",
    "test_labels = []\n",
    "for inputs, labels in test_dataloader:\n",
    "    outputs = model(inputs)\n",
    "    predictions = outputs.round().squeeze().detach().cpu().numpy()\n",
    "    labels = labels.detach().cpu().numpy()\n",
    "    test_predictions.extend(predictions)\n",
    "    test_labels.extend(labels)\n",
    "\n",
    "test_predictions = np.array(test_predictions)\n",
    "test_labels = np.array(test_labels)\n",
    "test_accuracy = (test_predictions == test_labels).mean()\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "cm = confusion_matrix(test_labels, test_predictions)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "ConfusionMatrixDisplay(cm).plot(ax=plt.gca())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988d5b84-9e8e-445c-944d-8b2d5e1eb51c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c256f8-9ac5-4a45-9772-3b4dd9f18908",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "task_nn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8a6ed7-219b-46d5-8f95-412925c3b019",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
